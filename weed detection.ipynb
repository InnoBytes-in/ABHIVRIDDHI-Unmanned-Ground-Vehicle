{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0abb0cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#Checking GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29738f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "     -------------------------------------- 59.0/59.0 kB 389.7 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (2.27.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (4.64.0)\n",
      "Requirement already satisfied: python-slugify in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (1.26.9)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.4)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73049 sha256=b0141548cc7e09f7e67218df932a72b2d35d848cc7d6ac76b495a01a9f132ca7\n",
      "  Stored in directory: c:\\users\\utkar\\appdata\\local\\pip\\cache\\wheels\\50\\0a\\6a\\77a4f3a534f0e5fd0909a376bbdfc88238a43eb2ac35947dc7\n",
      "Successfully built kaggle\n",
      "Installing collected packages: kaggle\n",
      "Successfully installed kaggle-1.5.12\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script kaggle.exe is installed in 'C:\\Users\\utkar\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383769ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some changes and permission in cloud\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!ls ~/.kaggle\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b4987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading Dataset\n",
    "!kaggle datasets download -d gavinarmstrong/open-sprayer-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053ddf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unziping dataset\n",
    "!unzip /content/open-sprayer-images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d8508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting unwanted data\n",
    "!rm -rf \"/content/docknet\"\n",
    "!rm -rf \"/content/open-sprayer-images.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4753dd2f",
   "metadata": {},
   "source": [
    "### Exploring Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a49d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Folders in dataset :\",os.listdir('/content/Docknet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1abf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Folders in traning set :\",os.listdir('/content/Docknet/train'))\n",
    "print(\"Folders in validation set :\",os.listdir('/content/Docknet/valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56cae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total images in 'train/docks' folder :\",len(os.listdir('/content/Docknet/train/docks')))\n",
    "print(\"Total images in 'train/notdocks' folder :\",len(os.listdir('/content/Docknet/train/notdocks')))\n",
    "print(\"Total images in 'valid/docks' folder :\",len(os.listdir('/content/Docknet/valid/docks')))\n",
    "print(\"Total images in 'valid/notdocks' folder :\",len(os.listdir('/content/Docknet/val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85b225c",
   "metadata": {},
   "source": [
    "### 1 . Pre - Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4070fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requried libraries\n",
    "## for image processing\n",
    "import cv2\n",
    "## for operating dataset\n",
    "import os\n",
    "## for visualizing graphs and images \n",
    "import matplotlib.pyplot as plt\n",
    "## #visualizing for loops \n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "## to display images only in colab\n",
    "from google.colab.patches import cv_imshow\n",
    "## for working with cnn's\n",
    "import keras\n",
    "## normalization function \n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "## data agumentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1530a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining image size\n",
    "img_size = 250 \n",
    "# pre-processing function \n",
    "def preprocess(filename):\n",
    "  ## reading images\n",
    "  img = cv2.imread(filename)\n",
    "  ## converting bgr to rgb color space\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  ## center crop\n",
    "  cropped_img = img[int((img.shape[0] - min(img.shape[0], img.shape[1]))/2): int((img.shape[0] + min(img.shape[0], img.shape[1]))/2), int((img.shape[1] - min(img.shape[0], img.shape[1]))/2): int((img.shape[1] + min(img.shape[0], img.shape[1]))/2), :]\n",
    "  ## image resizing \n",
    "  img_ = cv2.resize(cropped_img, (img_size,img_size))\n",
    "  ## converting pixel values to floats \n",
    "  img_normal = img_.astype(\"float32\")\n",
    "  ## applying normalization method\n",
    "  img_final = preprocess_input(img_normal)\n",
    "  ## returning image \n",
    "  return img_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c8ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example of pre processed image\n",
    "test_preimg = preprocess('/content/Docknet/train/docks/10021_11374_8504.jpg')\n",
    "print(\"pre-processed image\")\n",
    "print(test_preimg.shape)\n",
    "plt.imshow(test_preimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a8d42",
   "metadata": {},
   "source": [
    "### Data Agumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de6be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train dataset path\n",
    "train_path = '/content/Docknet/train/docks'\n",
    "#getting all images paths\n",
    "files = [f for f in os.listdir(train_path) if os.path.isfile(os.path.join(train_path, f))]\n",
    "#array to store all images after pre-processing\n",
    "images = []\n",
    "#array to store all labels\n",
    "labels = []\n",
    "#iterating to all files and storing into arrays\n",
    "for f in tqdm(files):\n",
    "  img = preprocess(os.path.join(train_path,f))\n",
    "  images.append(img)\n",
    "  labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ecec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total images in train set :\",len(images))\n",
    "print(\"Total labels in train set :\",len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f1f065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder for saving the augmented images\n",
    "os.mkdir('/content/Docknet/train/aug_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34fd3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data-agumentation \n",
    "import numpy as np\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    ## rescaling pixel values between [0,1]\n",
    "    rescale = 1./255,\n",
    "    ## moving image\n",
    "    shear_range = 0.2,\n",
    "    ## zooming into image\n",
    "    zoom_range = 0.2,\n",
    "    ## fliping image\n",
    "    horizontal_flip=True)\n",
    "i = 0\n",
    "## saving agumented images to aug_images folder\n",
    "for i in tqdm(range(5000)):\n",
    "  id_ = np.random.randint(len(images))\n",
    "  for batch in datagen.flow(np.expand_dims(images[id_], axis = 0), save_to_dir = '/content/Docknet/train/aug_images/', save_prefix = 'aug', save_format = 'jpeg'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c91292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking total images in augmented folder\n",
    "len(os.listdir('/content/Docknet/train/aug_images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33862ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepapre dataset for traning \n",
    "\n",
    "# part 1 : Loading all images in augumented folder \n",
    "path = '/content/Docknet/train/aug_images'    #path for folder\n",
    "files = [i for i in os.listdir(path) if os.path.isfile(os.path.join(path,i))]     #getting all filenames in folder \n",
    "for f in files:\n",
    "  image = preprocess(os.path.join(path,f))    #applying preprocessing function\n",
    "  images.append(image)    #storing preprocessed image\n",
    "  labels.append(0)        #storing corressponding label \n",
    "\n",
    "# part 2 : Loading all images in notdocks folder \n",
    "path = '/content/Docknet/train/notdocks'\n",
    "files = [i for i in os.listdir(path) if os.path.isfile(os.path.join(path,i))]\n",
    "for f in files:\n",
    "  image = preprocess(os.path.join(path,f))\n",
    "  images.append(image)\n",
    "  labels.append(1)\n",
    "\n",
    "# testing data loading \n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "# part 1 : Loading all images in docks folder \n",
    "\n",
    "path = '/content/Docknet/valid/docks'\n",
    "files = [i for i in os.listdir(path) if os.path.isfile(os.path.join(path,i))]\n",
    "for f in files:\n",
    "  image = preprocess(os.path.join(path,f))\n",
    "  test_images.append(image)\n",
    "  test_labels.append(0)\n",
    "# part 1 : Loading all images in notdocks folder \n",
    "path = '/content/Docknet/valid/notdocks'\n",
    "files = [i for i in os.listdir(path) if os.path.isfile(os.path.join(path,i))]\n",
    "for f in files:\n",
    "  image = preprocess(os.path.join(path,f))\n",
    "  test_images.append(image)\n",
    "  test_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdb3847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling traning data\n",
    "\n",
    "from random import shuffle\n",
    "#array to save shuffled images\n",
    "train_images = []\n",
    "#array to save shuffled labels\n",
    "train_labels = []\n",
    "index_shu = np.arange(len(images))\n",
    "shuffle(index_shu)\n",
    "for i in index_shu:\n",
    "  train_images.append(images[i])\n",
    "  train_labels.append(labels[i])\n",
    "# printing all shapes to cross check\n",
    "print(np.array(train_images).shape)\n",
    "print(np.array(train_labels).shape)\n",
    "print(np.array(test_images).shape)\n",
    "print(np.array(test_labels).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34806f8b",
   "metadata": {},
   "source": [
    "### 2 . Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f9b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining model\n",
    "def model():\n",
    "  #downloading InceptionV3 model weights \n",
    "  model = keras.applications.InceptionV3(include_top=False, input_shape=(250,250,3), weights='imagenet')\n",
    "  #adding global avg pooling layer to model\n",
    "  avg_layer = keras.layers.GlobalAveragePooling2D()(model.output)\n",
    "  #adding a dense layer\n",
    "  output_layer = keras.layers.Dense(2, activation='softmax')(avg_layer)\n",
    "  #combining model\n",
    "  final = keras.engine.training.Model(model.inputs, output_layer)\n",
    "  return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1085709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting model\n",
    "model = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1132d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary of model \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c8d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For fine tunning of model activating all layers except last 50 layers\n",
    "\n",
    "for layer in model.layers:\n",
    "  layer.trainable = True\n",
    "\n",
    "for layer in model.layers[:-50]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87ed6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model with binary crossentropy because of only two classes\n",
    "model.compile(\n",
    "    loss = 'binary_crossentropy',\n",
    "    optimizer = keras.optimizers.Adamax(learning_rate=1e-2),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63f449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traning data batch generator function\n",
    "\n",
    "import keras\n",
    "BS = 32  #defining batch size\n",
    "def train_gen(images,labels):\n",
    "  i=0\n",
    "  while True:           #running infinite loop\n",
    "    batch_imgs = np.array(images[i:i+BS])   #getting the batch size images from arrays\n",
    "    if (batch_imgs.shape[0] == 0):\n",
    "      break\n",
    "    batch_targets = np.array(labels[i:i+BS])\n",
    "    batch_labels = keras.utils.to_categorical(batch_targets, 2)  #converting labels to one-hot-encoding \n",
    "    i+=BS\n",
    "    yield batch_imgs, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dd8a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traning model\n",
    "history = model.fit_generator(\n",
    "    train_gen(train_images, train_labels), \n",
    "    steps_per_epoch=len(train_images) // BS // 8,\n",
    "    epochs= 8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1006b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b29626",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model accuracy and loss')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('loss')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101c6404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple functions for displaying and showing predicted label\n",
    "\n",
    "label = ['Docks','NotDocks']\n",
    "def preprocess_out(filename):\n",
    "  img = cv2.cvtColor(filename, cv2.COLOR_BGR2RGB)\n",
    "  cropped_img = img[int((img.shape[0] - min(img.shape[0], img.shape[1]))/2): int((img.shape[0] + min(img.shape[0], img.shape[1]))/2), int((img.shape[1] - min(img.shape[0], img.shape[1]))/2): int((img.shape[1] + min(img.shape[0], img.shape[1]))/2), :]\n",
    "  img_ = cv2.resize(cropped_img, (img_size,img_size))\n",
    "  img_normal = img_.astype(\"float32\")\n",
    "  img_final = preprocess_input(img_normal)\n",
    "  return img_final\n",
    "def predict(img_path):\n",
    "  img = cv2.imread(img_path)\n",
    "  cv_imshow(img)\n",
    "  imgTest = preprocess_out(img)\n",
    "  imgtest = np.array(imgTest)\n",
    "  imgtest = np.expand_dims(imgtest,axis=0)\n",
    "  pred = model.predict(imgtest)\n",
    "  val = np.argmax(pred)\n",
    "  print(val)\n",
    "  print('Predicted Label :', label[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c6ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing on a image from testing folder\n",
    "predict('/content/Docknet/valid/notdocks/1101_18561_27166.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b824e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict('/content/Docknet/valid/docks/851_15478_26020.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0093ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "train_predictions = []\n",
    "print(\"loading traning images !!!\")\n",
    "for i,file in enumerate(train_images):\n",
    "    file = np.reshape(file, [1, file.shape[0], file.shape[1], file.shape[2]])\n",
    "    prediction = model.predict(file)\n",
    "    prediction = np.argmax(prediction)\n",
    "    train_predictions.append(prediction)\n",
    "    \n",
    "test_predictions = []\n",
    "print(\"loading testing images !!!\")\n",
    "for i,file in enumerate(test_images):\n",
    "    file = np.reshape(file, [1, file.shape[0], file.shape[1], file.shape[2]])\n",
    "    prediction = model.predict(file)\n",
    "    prediction = np.argmax(prediction)\n",
    "    test_predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c76664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "train_acc = accuracy_score(np.array(train_predictions), \n",
    "                                     np.array(train_labels))\n",
    "test_acc = accuracy_score(np.array(test_predictions), \n",
    "                                     np.array(test_labels))\n",
    "\n",
    "print('Train Accuray:' + str(train_acc))\n",
    "print('Validation Accuray:' + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08f2d86",
   "metadata": {},
   "source": [
    "### CNN+SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cea98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from keras.models import Model\n",
    "svm = SVC(kernel='rbf', probability=True)\n",
    "model_feat = Model(inputs=model.input,outputs=model.get_layer('global_average_pooling2d').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2338f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extracting features from model\n",
    "feature_matrix = []\n",
    "for item in tqdm(train_images):\n",
    "    item = np.reshape(item, [1, item.shape[0], item.shape[1], item.shape[2]])\n",
    "    feat_train = model_feat.predict(item)\n",
    "    feature_matrix.append(feat_train)\n",
    "np.array(feature_matrix)\n",
    "\n",
    "s = len(feature_matrix)\n",
    "import pandas as pd\n",
    "feature_matrix = np.reshape(np.array(feature_matrix), (s, 2048))\n",
    "pd.DataFrame(np.array(feature_matrix)).to_csv(\"features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8902231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load generated feature matrix\n",
    "import pandas as pd\n",
    "test_fm = pd.read_csv('features.csv', index_col = 0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Save SVM Model\n",
    "import pickle\n",
    "from sklearn import model_selection\n",
    "svm.fit(test_fm,np.array(train_labels))\n",
    "print('fitting done !!!')\n",
    "filename = 'finalized_svm_model.sav'\n",
    "pickle.dump(svm, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe851d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction with CNN + Softmax\n",
    "img = preprocess(\"/content/Docknet/train/docks/3112_14280_24573.jpg\")\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "img = np.reshape(img, [1, img.shape[0], img.shape[1], img.shape[2]])\n",
    "prediction = model.predict(img)\n",
    "print(np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cfd0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction with CNN + SVM\n",
    "img = preprocess(\"/content/Docknet/train/docks/3112_14280_24573.jpg\")\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "img = np.reshape(img, [1, img.shape[0], img.shape[1], img.shape[2]])\n",
    "prediction = model_feat.predict(img)\n",
    "prediction = svm.predict(prediction)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9cd5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN + SVM\n",
    "import sklearn\n",
    "\n",
    "val_feature_matrix = []\n",
    "for item in test_images:\n",
    "    item = np.reshape(item, [1, item.shape[0], item.shape[1], item.shape[2]])\n",
    "    feat_train = model_feat.predict(item)\n",
    "    val_feature_matrix.append(feat_train)\n",
    "val_feature_matrix = np.array(val_feature_matrix)[:,0,:]\n",
    "\n",
    "print('Train Accuracy: ' + str(svm.score(test_fm,train_labels)))\n",
    "print('Validation Accuracy: ' + str(svm.score(val_feature_matrix,test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8c74bb",
   "metadata": {},
   "source": [
    "### CNN+Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a934b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN + Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
    "\n",
    "rf.fit(test_fm,np.array(train_labels))\n",
    "print('fitting done !!!')\n",
    "\n",
    "# Save RF Model\n",
    "import pickle\n",
    "from sklearn import model_selection\n",
    "filename = 'finalized_rf_model.sav'\n",
    "pickle.dump(rf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e508c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction with CNN + Random Forests Classifier\n",
    "img = preprocess(\"/content/Docknet/train/docks/3112_14280_24573.jpg\")\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "img = np.reshape(img, [1, img.shape[0], img.shape[1], img.shape[2]])\n",
    "prediction = model_feat.predict(img)\n",
    "prediction = rf.predict(prediction)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a6f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "val_feature_matrix = []\n",
    "for item in tqdm(test_images):\n",
    "    item = np.reshape(item, [1, item.shape[0], item.shape[1], item.shape[2]])\n",
    "    feat_train = model_feat.predict(item)\n",
    "    val_feature_matrix.append(feat_train)\n",
    "val_feature_matrix = np.array(val_feature_matrix)[:,0,:]\n",
    "\n",
    "print('Train Accuracy: ' + str(rf.score(test_fm,np.array(train_labels))))\n",
    "print('Validation Accuracy: ' + str(rf.score(val_feature_matrix,np.array(test_labels))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051647fe",
   "metadata": {},
   "source": [
    "### CNN + Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf00b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(test_fm,np.array(train_labels))\n",
    "print('fitting done !!!')\n",
    "\n",
    "import pickle\n",
    "filename = 'finalized_dt_model.sav'\n",
    "pickle.dump(dt, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4aad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocess(\"/content/Docknet/valid/notdocks/347_22859_1880.jpg\")\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "img = np.reshape(img, [1, img.shape[0], img.shape[1], img.shape[2]])\n",
    "prediction = model_feat.predict(img)\n",
    "prediction = dt.predict(prediction)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd35b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "val_feature_matrix = []\n",
    "for item in test_images:\n",
    "    item = np.reshape(item, [1, item.shape[0], item.shape[1], item.shape[2]])\n",
    "    feat_train = model_feat.predict(item)\n",
    "    val_feature_matrix.append(feat_train)\n",
    "val_feature_matrix = np.array(val_feature_matrix)[:,0,:]\n",
    "\n",
    "print('Train Accuracy: ' + str(dt.score(test_fm,np.array(train_labels))) + '\\n')\n",
    "print('Validation Accuracy: ' + str(dt.score(val_feature_matrix,np.array(test_labels))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f2af2f",
   "metadata": {},
   "source": [
    "### ROC curve and AUC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa68273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# CNN + SVM\n",
    "probs = svm.predict_proba(val_feature_matrix)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(np.array(test_labels), probs)\n",
    "print('AUC(SVM): %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(np.array(test_labels), probs)\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--', color = 'k')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.', label='CNN + SVM', color = 'b')\n",
    "\n",
    "# CNN + RF\n",
    "probs = rf.predict_proba(val_feature_matrix)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(np.array(test_labels), probs)\n",
    "print('AUC(RF): %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(np.array(test_labels), probs)\n",
    "# plot no skill\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.', label='CNN + Random Forest', color = 'c')\n",
    "\n",
    "# CNN + DT\n",
    "probs = dt.predict_proba(val_feature_matrix)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(np.array(test_labels), probs)\n",
    "print('AUC(DT): %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(np.array(test_labels), probs)\n",
    "# plot no skill\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.', label='CNN + Decision Tree', color = 'm')\n",
    "\n",
    "\n",
    "# CNN + Softmax\n",
    "probs = []\n",
    "for i,file in enumerate(test_images):\n",
    "    file = np.reshape(file, [1, file.shape[0], file.shape[1], file.shape[2]])\n",
    "    prediction = model.predict(file)\n",
    "    probs.append(prediction)\n",
    "probs = np.array(probs)\n",
    "probs = np.reshape(probs, (probs.shape[0],2))\n",
    "probs = probs[:,1]\n",
    "auc = roc_auc_score(np.array(test_labels), probs)\n",
    "print('AUC(Softmax): %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(np.array(test_labels), probs)\n",
    "# plot no skill\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.', label='CNN + Softmax', color = 'r')\n",
    "\n",
    "\n",
    "# show the plot\n",
    "plt.legend()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2119d58",
   "metadata": {},
   "source": [
    "### precision-recall curve and f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4f6872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision-recall curve and f1\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# CNN + SVM\n",
    "probs = svm.predict_proba(val_feature_matrix)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# predict class values\n",
    "yhat = svm.predict(val_feature_matrix)\n",
    "# calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(np.array(test_labels), probs)\n",
    "# calculate F1 score\n",
    "f1 = f1_score(np.array(test_labels), yhat)\n",
    "# calculate average precision score\n",
    "ap = average_precision_score(np.array(test_labels), probs)\n",
    "print('CNN + SVM: f1=%.3f ap=%.3f' % (f1, ap))\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0.5, 0.5], linestyle='--', color='k')\n",
    "# plot the precision-recall curve for the model\n",
    "pyplot.plot(recall, precision, marker='.', label='CNN + SVM', color='b')\n",
    "\n",
    "# CNN + RF\n",
    "probs = rf.predict_proba(val_feature_matrix)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# predict class values\n",
    "yhat = rf.predict(val_feature_matrix)\n",
    "# calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(np.array(test_labels), probs)\n",
    "# calculate F1 score\n",
    "f1 = f1_score(np.array(test_labels), yhat)\n",
    "# calculate average precision score\n",
    "ap = average_precision_score(np.array(test_labels), probs)\n",
    "print('CNN + RF: f1=%.3f ap=%.3f' % (f1, ap))\n",
    "# plot the precision-recall curve for the model\n",
    "pyplot.plot(recall, precision, marker='.', label='CNN + Random Forest', color='c')\n",
    "\n",
    "# CNN + DT\n",
    "probs = dt.predict_proba(val_feature_matrix)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# predict class values\n",
    "yhat = dt.predict(val_feature_matrix)\n",
    "# calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(np.array(test_labels), probs)\n",
    "# calculate F1 score\n",
    "f1 = f1_score(np.array(test_labels), yhat)\n",
    "# calculate average precision score\n",
    "ap = average_precision_score(np.array(test_labels), probs)\n",
    "print('CNN + DT: f1=%.3f ap=%.3f' % (f1, ap))\n",
    "# plot the precision-recall curve for the model\n",
    "pyplot.plot(recall, precision, marker='.', label='CNN + Decision Tree', color='m')\n",
    "\n",
    "# CNN + Softmax\n",
    "probs = []\n",
    "for i,file in enumerate(test_images):\n",
    "    file = np.reshape(file, [1, file.shape[0], file.shape[1], file.shape[2]])\n",
    "    prediction = model.predict(file)\n",
    "    probs.append(prediction)\n",
    "probs = np.array(probs)\n",
    "probs = np.reshape(probs, (probs.shape[0],2))\n",
    "probs = probs[:,1]\n",
    "\n",
    "yhat = []\n",
    "for i,file in enumerate(test_images):\n",
    "    file = np.reshape(file, [1, file.shape[0], file.shape[1], file.shape[2]])\n",
    "    prediction = model.predict(file)\n",
    "    prediction = np.argmax(prediction)\n",
    "    yhat.append(prediction)\n",
    "probs = np.array(probs)\n",
    "\n",
    "# calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(np.array(test_labels), probs)\n",
    "# calculate F1 score\n",
    "f1 = f1_score(np.array(test_labels), yhat)\n",
    "# calculate average precision score\n",
    "ap = average_precision_score(np.array(test_labels), probs)\n",
    "print('CNN + Softmax: f1=%.3f ap=%.3f' % (f1, ap))\n",
    "# plot the precision-recall curve for the model\n",
    "pyplot.plot(recall, precision, marker='.', label='CNN + Softmax', color='r')\n",
    "\n",
    "# show the plot\n",
    "plt.legend()\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1e09c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3282967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d61a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
